# ğŸ§  Interaktive Anwendung mit LLM (Language Model)

## ğŸš€ Was ist das hier eigentlich?

Willkommen in der Welt der KI! Diesmal mit einem besonders schlauen Kopf: **Qwen3 1.7B**, lokal ausgefÃ¼hrt Ã¼ber **[Ollama](https://ollama.com)**. Dieses Projekt zeigt dir, wie du ein Language Model so zÃ¤hmst, dass es per Texteingabe Buttons in einer Java-GUI klickt. Jep, das ist so nerdig und cool, wie es klingt.

Du schreibst z. B. *"DrÃ¼ck bitte den gelben Button"* und das System denkt nicht lange nach, sondern klickt los. Fast so, als hÃ¤tte deine Tastatur plÃ¶tzlich Finger bekommen.

---

## âš™ï¸ Wie das Ganze lÃ¤uft

1. **ğŸ’» Java-GUI**  
   Drei Buttons: Rot, Blau, Gelb. Du gibst einen Text ein, das LLM denkt kurz nach und drÃ¼ckt den passenden Button.  

2. **ğŸ§  LLM mit Ollama (Qwen3 1.7B)**  
   Statt einem externen Server lÃ¤uft jetzt **Qwen3** lokal Ã¼ber **Ollama** eine super einfache MÃ¶glichkeit, LLMs lokal zu nutzen (keine Cloud, keine Panik, alles offline).  

3. **ğŸ Python MCP-Server (`mcp_server.py`)**  
   Der gute alte Entscheidungsserver bleibt erhalten, nur dass er jetzt direkt mit Ollama spricht. Er analysiert den Modell-Output und klickt auf Basis der gefundenen Farbe den richtigen Button.

---

## ğŸ› ï¸ Vorbereitung: Was du brauchst

### ğŸ“… 1. Installiere Ollama

Falls du Ollama noch nicht kennst, es ist quasi *Docker fÃ¼r KI-Modelle*, aber mit einem Turbo-Knopf.

ğŸ‘‰ [Download Ollama](https://ollama.com/download)

Nach der Installation kannst du Ã¼berprÃ¼fen, ob alles lÃ¤uft:

```bash
ollama --version
```

Wenn das klappt, weiter mit Schritt 2.

---

### ğŸ§  2. Qwen3 1.7B Modell herunterladen

Einmal das Modell in die Ollama-Welt holen:

```bash
ollama pull qwen3:1.7b
```

Du kannst auch andere Modelle probieren, aber dieses Projekt wurde auf `qwen3:1.7b` abgestimmt, also bleib am besten erstmal dabei.

---

### ğŸ 3. Python-AbhÃ¤ngigkeiten installieren

Ã–ffne ein Terminal im Projektordner und installiere die notwendigen Pakete:

**macOS/Linux:**
```bash
pip3 install -r requirements.txt
```

**Windows:**
```bash
pip install -r requirements.txt
```

---

## â˜• Die Java-Anwendung starten

Sobald Ollama lÃ¤uft und das Modell bereitsteht, Ã¼bernimmt die Java-Anwendung den Rest. Beim Start Ã¶ffnet sie automatisch den MCP-Server, der mit Ollama spricht. Keine Extra-Server-Skripte nÃ¶tig.

---

## âœ¨ Benutzung

1. Starte die Java-Anwendung.
2. Gib einen Satz wie `"Bitte drÃ¼ck den roten Button"` ein.
3. Das Modell interpretiert deine Eingabe.
4. Der Button mit der entsprechenden Farbe wird geklickt.
5. Du bekommst visuelles Feedback direkt in der GUI.

ğŸ’¡ Tipp: Das funktioniert auch mit natÃ¼rlichsprachlichen Formulierungen wie:  
*"Ich mag Blau, klick den Button bitte."*

---

## âš ï¸ Hinweise & Tipps

- Achte darauf, dass **Ollama im Hintergrund lÃ¤uft**, bevor du die Java-Anwendung startest.
- Das Modell `qwen3:1.7b` muss einmalig mit `ollama pull` heruntergeladen werden â€“ danach bleibt es lokal verfÃ¼gbar.
- Wenn du unter Windows arbeitest:  
  **Pass im Java-Code Zeile 102 und 108 an â€“ `python3` â” `python`**, sonst startet das Skript nicht richtig.

---

## ğŸ› ï¸ Fehlerbehebung

- **Java-GUI startet, aber nix passiert?**  
  â†’ LÃ¤uft Ollama? Modell geladen? Terminal sagt was von "No model found"? Dann hast du vermutlich `ollama pull qwen3:1.7b` vergessen.

- **Modell antwortet nicht sinnvoll?**  
  â†’ Achte auf einfache Farbangaben in deinen Prompts. "Tiefschwarz" versteht das Modell vielleicht nicht als `"schwarz"` (und Schwarz ist hier eh kein Button ğŸ˜‰).

- **Ports blockiert?**  
  â†’ StandardmÃ¤ÃŸig lÃ¤uft der MCP-Server auf Port `5001`. Achte darauf, dass nix anderes den Port blockiert (manche IDEs oder Jupyter-Instanzen sind hier gern Spielverderber).

---

## ğŸ§ª Fazit

Mit **Ollama + Qwen** hast du ein elegantes, lokales LLM-Setup, das dir eine smarte Interaktion mit deiner Java-GUI ermÃ¶glicht, ganz ohne Cloud, Registrierung oder API-SchlÃ¼ssel. Einfach: installieren, starten, prompten. âœ¨

Wenn du Lust auf mehr hast: Denk mal Ã¼ber Sprachsteuerung, Voice2Text oder weiterfÃ¼hrende Aktionen nach. Dieses Setup ist ein groÃŸartiger Einstiegspunkt!
